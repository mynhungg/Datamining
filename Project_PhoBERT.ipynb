{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mynhungg/Datamining/blob/main/Project_PhoBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE96HGkHDfUn"
      },
      "source": [
        "## Import thư viện\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pry2ytalDk-1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2exXVQJxUiI"
      },
      "source": [
        "\n",
        "\n",
        "##1.   Load model BERT\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "M_FIEJpOa5jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8k2L-iCxUNi",
        "outputId": "cc5059f9-e935-4647-b709-231b33c05a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "path = \"/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3\"\n",
        "os.chdir(path)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBipNT9pEHIS"
      },
      "source": [
        "\n",
        "\n",
        "1.   Cài package\n",
        "*   fairseq\n",
        "*   fastBPE\n",
        "*   vncorenlp\n",
        "*   transformers\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQd_I_nFEO8t",
        "outputId": "29e3b3b3-f500-4365-c884-15e9b07382a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fairseq in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (0.29.34)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.0.7)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2022.10.31)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.3.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.65.0)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.7.3)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.22.4)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.5.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.7.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (16.0.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastbpe in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vncorenlp in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vncorenlp) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install fairseq\n",
        "!pip3 install fastbpe\n",
        "!pip3 install vncorenlp\n",
        "!pip3 install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoFLSFvREpSO"
      },
      "source": [
        "\n",
        "2.   Download model pretrain từ [PhoBERT](https://github.com/VinAIResearch/PhoBERT)\n",
        "\n",
        "Project sử dụng pretrain model BERT base được huấn luyện từ package fairseq.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps6uTKkFE9Ka",
        "outputId": "e85e6470-0537-47f5-ced3-7f2cd1e05219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-23 04:40:16--  https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n",
            "Resolving public.vinai.io (public.vinai.io)... 13.35.7.109, 13.35.7.61, 13.35.7.129, ...\n",
            "Connecting to public.vinai.io (public.vinai.io)|13.35.7.109|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1243308020 (1.2G) [application/x-tar]\n",
            "Saving to: ‘PhoBERT_base_fairseq.tar.gz’\n",
            "\n",
            "PhoBERT_base_fairse 100%[===================>]   1.16G  26.1MB/s    in 26s     \n",
            "\n",
            "2023-05-23 04:40:42 (45.1 MB/s) - ‘PhoBERT_base_fairseq.tar.gz’ saved [1243308020/1243308020]\n",
            "\n",
            "PhoBERT_base_fairseq/\n",
            "PhoBERT_base_fairseq/bpe.codes\n",
            "PhoBERT_base_fairseq/model.pt\n",
            "PhoBERT_base_fairseq/dict.txt\n"
          ]
        }
      ],
      "source": [
        "!wget https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n",
        "!tar -xzvf PhoBERT_base_fairseq.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOhTQMS6qLad",
        "outputId": "037453bd-7b24-4994-90de-5bd0a166046b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-23 04:41:14--  https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n",
            "Resolving public.vinai.io (public.vinai.io)... 13.35.7.109, 13.35.7.61, 13.35.7.129, ...\n",
            "Connecting to public.vinai.io (public.vinai.io)|13.35.7.109|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322405979 (307M) [application/x-tar]\n",
            "Saving to: ‘PhoBERT_base_transformers.tar.gz’\n",
            "\n",
            "PhoBERT_base_transf 100%[===================>] 307.47M  41.4MB/s    in 6.8s    \n",
            "\n",
            "2023-05-23 04:41:21 (45.0 MB/s) - ‘PhoBERT_base_transformers.tar.gz’ saved [322405979/322405979]\n",
            "\n",
            "PhoBERT_base_transformers/\n",
            "PhoBERT_base_transformers/config.json\n",
            "PhoBERT_base_transformers/bpe.codes\n",
            "PhoBERT_base_transformers/model.bin\n",
            "PhoBERT_base_transformers/dict.txt\n"
          ]
        }
      ],
      "source": [
        "!wget https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n",
        "!tar -xzvf PhoBERT_base_transformers.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7vB0Ri1FcQi"
      },
      "source": [
        "Sau khi download và giải nén pretrain file chúng ta sẽ kiểm tra thấy bên trong folder sẽ bao gồm 3 files đó là `bpe.codes, dict.txt, model.pt` có tác dụng như sau:\n",
        "\n",
        "* bpe.codes: Là BPE token mà mô hình đã áp dụng để mã hóa văn bản sang index.\n",
        "\n",
        "* dict.txt: Từ điển của bộ dữ liệu huấn luyện.\n",
        "\n",
        "* model.pt: File lưu trữ của mô hình trên pytorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfRM6lwEETBU",
        "outputId": "5dfe538b-0a33-4b6c-c28c-7c81b185fcac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bpe.codes  dict.txt  model.pt\n"
          ]
        }
      ],
      "source": [
        "!ls PhoBERT_base_fairseq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfhtNdHPFnH7"
      },
      "source": [
        "## 2. Load model pretrain PhoBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z_0VK8PFzBS",
        "outputId": "6785fb60-f6c8-4f31-f3b1-866b9511a553"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaHubInterface(\n",
              "  (model): RobertaModel(\n",
              "    (encoder): RobertaEncoder(\n",
              "      (sentence_encoder): TransformerEncoder(\n",
              "        (dropout_module): FairseqDropout()\n",
              "        (embed_tokens): Embedding(64001, 768, padding_idx=1)\n",
              "        (embed_positions): LearnedPositionalEmbedding(258, 768, padding_idx=1)\n",
              "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (layers): ModuleList(\n",
              "          (0-11): 12 x TransformerEncoderLayerBase(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (lm_head): RobertaLMHead(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (classification_heads): ModuleDict()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Load the model in fairseq\n",
        "from fairseq.models.roberta import RobertaModel\n",
        "phoBERT = RobertaModel.from_pretrained('PhoBERT_base_fairseq', checkpoint_file='model.pt')\n",
        "phoBERT.eval()  # disable dropout (or leave in train mode to finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic6PN1x1Fuka"
      },
      "source": [
        "Ta có thể thấy kiến trúc RoBERTa đã giữa lại 12 block sub-layers là các multi-head attention ở phase Encoder và thêm một linear projection layer ở cuối để tạo ra một embedding cho từ hiện tại."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vbo_zvbF9pk"
      },
      "source": [
        "**Áp dụng BPE tokenize trong BERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96AYiQE7Gi8A",
        "outputId": "badcd56f-87c6-4d50-8459-e1ed480cbebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fairseq in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (0.29.34)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.0.7)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2022.10.31)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.3.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.65.0)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.7.3)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.22.4)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.5.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.7.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (16.0.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastBPE in /usr/local/lib/python3.10/dist-packages (0.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install fairseq\n",
        "!pip3 install fastBPE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe4LlyVcGle4"
      },
      "source": [
        "Load model pretrain `RoBERTa`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02CebeW2GplJ",
        "outputId": "7a282451-ac97-446b-ef74-192fbd4fd497"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaHubInterface(\n",
              "  (model): RobertaModel(\n",
              "    (encoder): RobertaEncoder(\n",
              "      (sentence_encoder): TransformerEncoder(\n",
              "        (dropout_module): FairseqDropout()\n",
              "        (embed_tokens): Embedding(64001, 768, padding_idx=1)\n",
              "        (embed_positions): LearnedPositionalEmbedding(258, 768, padding_idx=1)\n",
              "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (layers): ModuleList(\n",
              "          (0-11): 12 x TransformerEncoderLayerBase(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (lm_head): RobertaLMHead(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (classification_heads): ModuleDict()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Load the model in fairseq\n",
        "from fairseq.models.roberta import RobertaModel\n",
        "phoBERT = RobertaModel.from_pretrained('PhoBERT_base_fairseq', checkpoint_file='model.pt')\n",
        "phoBERT.eval()  # disable dropout (or leave in train mode to finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loemyMm4GuUO"
      },
      "source": [
        "Khai báo bpe tokenizer và thực hiện token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "LuwKZO3LGw--",
        "outputId": "287dd78d-242d-4734-d229-9eb3f26378ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens list :  tensor([    0, 11623, 31433,   453, 44334,  2080,  5922,    57,   934,  8181,\n",
            "        31686,  3078,     2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tôn Ngộ Không phò Đường Tăng đi Tây Trúc thỉnh kinh'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from fairseq.data.encoders.fastbpe import fastBPE\n",
        "\n",
        "# Khởi tạo Byte Pair Encoding cho PhoBERT\n",
        "class BPE():\n",
        "  bpe_codes = 'PhoBERT_base_fairseq/bpe.codes'\n",
        "\n",
        "args = BPE()\n",
        "phoBERT.bpe = fastBPE(args) #Incorporate the BPE encoder into PhoBERT\n",
        "tokens = phoBERT.encode('Tôn Ngộ Không phò Đường Tăng đi Tây Trúc thỉnh kinh')\n",
        "print('tokens list : ', tokens)\n",
        "# Decode ngược lại thành câu từ chuỗi index token\n",
        "phoBERT.decode(tokens)  # 'Hello world!'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJmVa_48Gv6S"
      },
      "source": [
        "Down load package VnCoreNLP để tokenize các câu văn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNtWrjCeG77a",
        "outputId": "2f76ff27-420b-4b38-8208-9b6e5974138e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-23 04:42:42--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27412575 (26M) [application/octet-stream]\n",
            "Saving to: ‘VnCoreNLP-1.1.1.jar’\n",
            "\n",
            "VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M  29.2MB/s    in 0.9s    \n",
            "\n",
            "2023-05-23 04:42:43 (29.2 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n",
            "\n",
            "--2023-05-23 04:42:43--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 526544 (514K) [application/octet-stream]\n",
            "Saving to: ‘vi-vocab’\n",
            "\n",
            "vi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-05-23 04:42:44 (11.3 MB/s) - ‘vi-vocab’ saved [526544/526544]\n",
            "\n",
            "--2023-05-23 04:42:44--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 128508 (125K) [text/plain]\n",
            "Saving to: ‘wordsegmenter.rdr’\n",
            "\n",
            "wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-05-23 04:42:44 (4.93 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!mkdir -p vncorenlp/models/wordsegmenter\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
        "!mv VnCoreNLP-1.1.1.jar vncorenlp/ \n",
        "!mv vi-vocab vncorenlp/models/wordsegmenter/\n",
        "!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWv4Y67dHhM_"
      },
      "source": [
        "Gỉa sử chúng ta có câu gốc là `Tôn Ngộ Không phò Đường Tăng đi thỉnh kinh tại Tây Trúc`. Từ được ẩn đi trong câu là `phò` sẽ được thay thế bằng token `<mask>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvyS1c2sHh_D",
        "outputId": "a6665f91-1a18-4f10-885e-f86718b897ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_masked_tok: \n",
            " Tôn_Ngộ_Không  <mask> Đường Tăng đi thỉnh_kinh tại Tây_Trúc\n"
          ]
        }
      ],
      "source": [
        "from vncorenlp import VnCoreNLP\n",
        "rdrsegmenter = VnCoreNLP(\"vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m') \n",
        "\n",
        "text = 'Tôn Ngộ Không phò Đường Tăng đi thỉnh kinh tại Tây Trúc'\n",
        "text_masked = 'Học sinh được  <mask> do dịch covid-19'\n",
        "# Tokenize câu gốc và thay từ phò bằng <mask>\n",
        "words = rdrsegmenter.tokenize(text)[0]\n",
        "for i, token in enumerate(words):\n",
        "  if token == 'phò':\n",
        "    words[i] = ' <mask>'\n",
        "text_masked_tok = ' '.join(words)\n",
        "print('text_masked_tok: \\n', text_masked_tok)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpfdmhujHkag"
      },
      "source": [
        "Tìm ra top 10 từ thích hợp nhất cho vị trí `<mask>` tại câu trên."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLPbdhtdIMPK"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvbV1GtKHk59",
        "outputId": "d75ad7af-4b27-4e46-c4ef-0dc1add433d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total probability:  0.8735209610313177\n",
            "Input sequence:  Tôn_Ngộ_Không  <mask> Đường Tăng đi thỉnh_kinh tại Tây_Trúc\n",
            "Top 10 in mask: \n",
            "Tôn_Ngộ_Không và Đường Tăng đi thỉnh_kinh tại Tây_Trúc\n",
            "Tôn_Ngộ_Không đưa Đường Tăng đi thỉnh_kinh tại Tây_Trúc\n",
            "Tôn_Ngộ_Không cõng Đường Tăng đi thỉnh_kinh tại Tây_Trúc\n",
            "Tôn_Ngộ_Không hộ_tống Đường Tăng đi thỉnh_kinh tại Tây_Trúc\n",
            "Tôn_Ngộ_Không cùng Đường Tăng đi thỉnh_kinh tại Tây_Trúc\n",
            "Tôn_Ngộ_Không chở Đường Tăng đi thỉnh_kinh tại Tây_Trúc\n",
            "Tôn_Ngộ_Không theo Đường Tăng đi thỉnh_kinh tại Tây_Trúc\n",
            "Tôn_Ngộ_Không dẫn Đường Tăng đi thỉnh_kinh tại Tây_Trúc\n",
            "Tôn_Ngộ_Không , Đường Tăng đi thỉnh_kinh tại Tây_Trúc\n",
            "Tôn_Ngộ_Không tháp_tùng Đường Tăng đi thỉnh_kinh tại Tây_Trúc\n"
          ]
        }
      ],
      "source": [
        "from fairseq.data.encoders.fastbpe import fastBPE  \n",
        "from fairseq import options  \n",
        "import numpy as np\n",
        "\n",
        "# Khởi tạo Byte Pair Encoding cho PhoBERT\n",
        "class BPE():\n",
        "  bpe_codes = 'PhoBERT_base_fairseq/bpe.codes'\n",
        "args = BPE()\n",
        "phoBERT.bpe = fastBPE(args) #Incorporate the BPE encoder into PhoBERT\n",
        "\n",
        "# Filling marks  \n",
        "topk_filled_outputs = phoBERT.fill_mask(text_masked_tok, topk=10) \n",
        "topk_probs = [item[1] for item in topk_filled_outputs]\n",
        "print('Total probability: ', np.sum(topk_probs))\n",
        "print('Input sequence: ', text_masked_tok)\n",
        "print('Top 10 in mask: ')\n",
        "for i, output in enumerate(topk_filled_outputs): \n",
        "  print(output[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wmrmj1GHsTA"
      },
      "source": [
        "## 7. Extract feature cho các từ\n",
        "\n",
        "Chúng ta có thể tìm ra được các véc tơ embedding cho từng từ trong câu từ mô hình BERT như sau:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsNPoeCSHqCa"
      },
      "outputs": [],
      "source": [
        "#from fairseq.data.encoders.fastbpe import fastBPE\n",
        "\n",
        "# Khởi tạo Byte Pair Encoding cho PhoBERT\n",
        "#class BPE():\n",
        "  #bpe_codes = 'PhoBERT_base_fairseq/bpe.codes'\n",
        "\n",
        "#args = BPE()\n",
        "#phoBERT.bpe = fastBPE(args) #Incorporate the BPE encoder into PhoBERT\n",
        "#doc = phoBERT.extract_features_aligned_to_words('học_sinh cấp 3 được đến trường sau nghỉ dịch covid')\n",
        "\n",
        "#for tok in doc:\n",
        " #   print('{:10}{} (...) {}'.format(str(tok), tok.vector[:5], tok.vector.size()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXj__KAnIN5L"
      },
      "source": [
        "## 8. Bài toán classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6YIYujoIRw0"
      },
      "source": [
        "### 8.2. Dữ liệu\n",
        "\n",
        "sử dụng dữ liệu [VNTC](https://github.com/duyvuleo/VNTC.git) với các bài báo đã được sắp xếp theo 10 topics. Bộ dữ liệu bao gồm 33 nghìn bài báo trên tập train và 50 nghìn bài báo trên tập test có phân bố số lượng theo topics như sau:\n",
        "\n",
        "![](https://imgur.com/1lDTdC1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_NPXfX2IYkh"
      },
      "source": [
        "8.2.1. Đọc và lưu dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B4CIrquLfUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44123b2-d240-4593-bb44-69abc1fe319d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access '/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/.git/hooks/post-checkout': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!chmod +x /content/gdrive/MyDrive/Colab\\ Notebooks/PhoBERT_VNTC_3/VNTC/.git/hooks/post-checkout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU-VqmAYIcP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec19d1ff-06e0-4c27-a438-e73e8f46107c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VNTC'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Total 39 (delta 0), reused 0 (delta 0), pack-reused 39\u001b[K\n",
            "Unpacking objects: 100% (39/39), 160.90 MiB | 5.17 MiB/s, done.\n",
            "Updating files: 100% (15/15), done.\n",
            "Filtering content: 100% (2/2), 168.95 MiB | 30.81 MiB/s, done.\n",
            "fatal: cannot exec '/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/.git/hooks/post-checkout': Permission denied\n",
            "Stats.txt  Test_Full.rar  Train_Full.rar\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/duyvuleo/VNTC.git\n",
        "!ls VNTC/Data/10Topics/Ver1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHWU-45D3-FF"
      },
      "source": [
        "Extract file dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpCcXOiWzUfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "4342f743-defe-4df4-8dad-50122a594449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: patool in /usr/local/lib/python3.10/dist-packages (1.12)\n",
            "patool: Extracting /content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1/Train_Full.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1/Train_Full.rar\"\n",
            "patool:     with cwd='/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1'\n",
            "patool: ... /content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1/Train_Full.rar extracted to `/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "!pip install patool\n",
        "import patoolib\n",
        "# Specify the path to the RAR file\n",
        "rar_file_path = '/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1/Train_Full.rar'\n",
        "\n",
        "# Specify the destination directory for extraction\n",
        "destination_dir = '/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1'\n",
        "\n",
        "# Extract the RAR file\n",
        "patoolib.extract_archive(rar_file_path, outdir=destination_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAy2qZiT5gvs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "2e6f3bc8-0854-43a2-88b8-db9fefdcb903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting /content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1/Test_Full.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1/Test_Full.rar\"\n",
            "patool:     with cwd='/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1'\n",
            "patool: ... /content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1/Test_Full.rar extracted to `/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Specify the path to the RAR file\n",
        "rar_file_path = '/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1/Test_Full.rar'\n",
        "\n",
        "# Specify the destination directory for extraction\n",
        "destination_dir = '/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1'\n",
        "\n",
        "# Extract the RAR file\n",
        "patoolib.extract_archive(rar_file_path, outdir=destination_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS2FYMBnIbwc"
      },
      "source": [
        "Sau khi đã download dữ liệu về, chúng ta sẽ đọc và lưu các bài báo vào những list chứa nội dung và nhãn tương ứng theo 2 folders train và test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNnrjdQJY6Wq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "777b02a5-4895-457d-c841-0909360288f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33759/33759 [01:01<00:00, 551.22it/s]\n",
            "100%|██████████| 33759/33759 [00:40<00:00, 823.52it/s]\n"
          ]
        }
      ],
      "source": [
        "import glob2\n",
        "from tqdm import tqdm\n",
        "\n",
        "train_path = '/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1/Train_Full/*/*.txt'\n",
        "test_path = '/content/gdrive/MyDrive/Colab Notebooks/PhoBERT_VNTC_3/VNTC/Data/10Topics/Ver1.1/Test_Full/*/*.txt'\n",
        "\n",
        "# Hàm đọc file txt\n",
        "def read_txt(path):\n",
        "  with open(path, 'r', encoding='utf-16') as f:\n",
        "    data = f.read()\n",
        "  return data\n",
        "\n",
        "# Hàm tạo dữ liệu huấn luyện cho tập train và test\n",
        "def make_data(path):\n",
        "  texts = []\n",
        "  labels = []\n",
        "  for file_path in tqdm(glob2.glob(train_path)):\n",
        "    try:\n",
        "      content = read_txt(file_path)\n",
        "      label = file_path.split('/')[11]\n",
        "      texts.append(content)\n",
        "      labels.append(label)\n",
        "    except:\n",
        "      next\n",
        "  return texts, labels\n",
        "\n",
        "text_train, label_train = make_data(train_path)\n",
        "text_test, label_test = make_data(test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqekoMSpIoy7"
      },
      "source": [
        "Tạo các hàm lưu trữ lại các list nội dung và nhãn và load lại cho lượt huấn luyện sau."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRfUAZ8SIqAK"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "def _save_pkl(path, obj):\n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump(obj, f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apfxtXJ--6Ih"
      },
      "outputs": [],
      "source": [
        "def _load_pkl(path):\n",
        "  with open(path, 'rb') as f:\n",
        "    obj = pickle.load(f)\n",
        "  return obj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znzItcjM-8Py"
      },
      "outputs": [],
      "source": [
        "# Lưu lại các files\n",
        "_save_pkl('text_train.pkl', text_train)\n",
        "_save_pkl('label_train.pkl', label_train)\n",
        "_save_pkl('text_test.pkl', text_test)\n",
        "_save_pkl('label_test.pkl', label_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h0Pmup6IrJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac8b673-45ad-49e4-e63f-d5d6fcd3484e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text content:\n",
            " Các nhà khoa học nói về ô nhiễm tại hố chôn gà dịch \n",
            "Trong những ngày qua, có nhiều ý kiến phản ánh của người dân về tình trạng ô nhiễm tại các điểm chôn gà chết của TP HCM. Ở các hố chôn, nước dịch trào ra, thoát khí nặng mùi, nhất là vào những hôm trời nóng bức. VnExpress đã trao đổi với một số nhà khoa học và quản lý môi trường về vấn đề này.\n",
            "Giáo sư, Tiến sĩ Tưởng Thị Hội, giảng viên Viện Khoa học và công nghệ Môi trường, ĐH Bách Khoa Hà Nội: Động vật khi chôn sâu trong lòng đất sẽ bị phân hủy dưới dạng hiếu khí và yếm khí, tạo ra những hợp chất dạng khác nhau như thể lỏng hoặc thể khí. Các dịch lỏng phát sinh có thể ngấm vào đất và gây ô nhiễm nguồn nước. Điều này trước kia cũng đã xảy ra ở nghĩa trang Văn Điển, Hà Nội. Các khí tạo thành trong quá trình phân hủy chất hữu cơ như CH4, NH3, H2S, CO2 thoát ra ngoài môi trường sẽ tạo ra mùi hôi, gây độc hại đến môi trường sống.\n",
            "Giáo sư Nguyễn Công Mẫn, Phó chủ tịch Viện Địa kỹ thuật thuộc Liên hiệp các Hội khoa học kỹ thuật Việt Nam: Các chất hữu cơ khi phân hủy trong các bãi chôn lấp sẽ tạo ra nước rác trong đó có chứa các hợp chất hữu cơ, canxi, xương& Đặc biệt, đối với các hố chôn gà chết do dịch thì còn chứa cả các vi trùng gây bệnh. Do vậy, cần phải có biện pháp thích hợp để xử lý. Thông thường, các hố chôn lấp phải có đường thoát nước rác riêng dẫn ra nơi xử lý, nếu không chúng sẽ ngấm vào trong đất, phát tán ra môi trường xung quanh. Khả năng nguy cơ gây ô nhiễm nước ngầm tuỳ thuộc vào tính chất địa tầng ở từng nơi. Điều này phải kiểm tra và xét nghiệm trên thực tế mới có kết quả chính xác.\n",
            "Bà Đoàn Thị Tới, Trưởng phòng Quản lý môi trường, Sở Tài nguyên  Môi trường TP HCM: Chúng tôi cùng với Trung tâm Y tế dự phòng đã tiến hành lấy mẫu tại một số điểm chôn gà để có kết quả chính xác về nguy cơ ô nhiễm nước. Theo đúng kỹ thuật thì sau khi lấy mẫu 5 ngày mới bắt đầu xét nghiệm và 7 ngày sau mới có kết quả. Nói chung, các hố chôn đều tại vị trí cao, khô ráo, chôn theo đúng quy trình kỹ thuật nên khả năng ô nhiễm là không lớn. Chỉ có tại khu vực huyện Nhà Bè có là vùng thấp, ngập nước nên cần phải có thời gian để có kết luận chính xác về sự ô nhiễm nước mặt. Còn các giếng khoan tại đây có độ sâu khoảng 100 m trong khi hố chôn chỉ có 1-2 m nên nguy cơ ô nhiễm nước ngầm rất khó xảy ra. Về môi trường đất, do thời gian chôn chưa lâu nên chưa phát hiện được dấu hiệu ô nhiễm. Những trường hợp người dân phản ánh về tình trạng mùi xú uế phát sinh từ các hố chôn, đây là điều bình thường trong quá trình phân huỷ chất hữu cơ. Chỉ trong một thời gian ngắn là sẽ không còn hiện tượng này nữa. Hiện tại, chúng tôi cùng với Trung tâm Y tế dự phòng chỉ tiến hành đắp thêm đất, rải thêm vôi để giảm ô nhiễm.\n",
            "Giáo sư Hoàng Thuỷ Long trả lời trực tuyến về dịch cúm A(30/01/2004)\n",
            "Một chủ trại gà ở Long An chết vì bệnh cúm(30/01/2004)\n",
            "Các trường bán trú 'tẩy chay' thịt gia cầm(29/01/2004)\n",
            "Chim cảnh vẫn được mua bán tại TP HCM(29/01/2004)\n",
            "Phát hiện thêm 15 ổ dịch cúm gà mới(29/01/2004)\n",
            "\n",
            "\n",
            "label:\n",
            " Chinh tri Xa hoi\n"
          ]
        }
      ],
      "source": [
        "print('text content:\\n', text_train[0])\n",
        "print('label:\\n', label_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuwXUwc-JQWS"
      },
      "source": [
        "#### 8.2.2. Tokenize nội dung\n",
        "\n",
        "Tiếp theo ta sẽ tokenize các câu văn sang chuỗi index và padding câu văn về cùng một độ dài."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkyGDtoAImBh"
      },
      "outputs": [],
      "source": [
        "max_sequence_length = 500\n",
        "\n",
        "def convert_lines(lines, vocab, bpe):\n",
        "  '''\n",
        "  lines: list các văn bản input\n",
        "  vocab: từ điển dùng để encoding subwords\n",
        "  bpe: \n",
        "  '''\n",
        "  # Khởi tạo ma trận output\n",
        "  outputs = np.zeros((len(lines), max_sequence_length)) # --> shape (number_lines, max_seq_len)\n",
        "  # Index của các token cls (đầu câu), eos (cuối câu), padding (padding token)\n",
        "  cls_id = 0\n",
        "  eos_id = 2\n",
        "  pad_id = 1\n",
        "\n",
        "  for idx, row in tqdm(enumerate(lines), total=len(lines)): \n",
        "    # Mã hóa subwords theo byte pair encoding(bpe)\n",
        "    subwords = bpe.encode('<s> '+ row +' </s>')\n",
        "    input_ids = vocab.encode_line(subwords, append_eos=False, add_if_not_exist=False).long().tolist()\n",
        "    # Truncate input nếu độ dài vượt quá max_seq_len\n",
        "    if len(input_ids) > max_sequence_length: \n",
        "      input_ids = input_ids[:max_sequence_length] \n",
        "      input_ids[-1] = eos_id\n",
        "    else:\n",
        "      # Padding nếu độ dài câu chưa bằng max_seq_len\n",
        "      input_ids = input_ids + [pad_id, ]*(max_sequence_length - len(input_ids))\n",
        "    \n",
        "    outputs[idx,:] = np.array(input_ids)\n",
        "  return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTC8LVPKIZJj"
      },
      "source": [
        "### 8.3. Tokenize Input và output\n",
        "\n",
        "* Chuẩn bị X input: Tokenize nội dung các văn bản sang chuỗi indices.\n",
        "\n",
        "* Chuẩn bị y output: Encoding các label output thành indices đánh dấu số thứ tự của văn bản."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HG9cds-j8is"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "max_sequence_length = 256\n",
        "def convert_lines(lines, vocab, bpe):\n",
        "  '''\n",
        "  lines: list các văn bản input\n",
        "  vocab: từ điển dùng để encoding subwords\n",
        "  bpe: \n",
        "  '''\n",
        "  # Khởi tạo ma trận output\n",
        "  outputs = np.zeros((len(lines), max_sequence_length), dtype=np.int32) # --> shape (number_lines, max_seq_len)\n",
        "  # Index của các token cls (đầu câu), eos (cuối câu), padding (padding token)\n",
        "  cls_id = 0\n",
        "  eos_id = 2\n",
        "  pad_id = 1\n",
        "\n",
        "  for idx, row in tqdm(enumerate(lines), total=len(lines)): \n",
        "    # Mã hóa subwords theo byte pair encoding(bpe)\n",
        "    subwords = bpe.encode('<s> '+ row +' </s>')\n",
        "    input_ids = vocab.encode_line(subwords, append_eos=False, add_if_not_exist=False).long().tolist()\n",
        "    # Truncate input nếu độ dài vượt quá max_seq_len\n",
        "    if len(input_ids) > max_sequence_length: \n",
        "      input_ids = input_ids[:max_sequence_length] \n",
        "      input_ids[-1] = eos_id\n",
        "    else:\n",
        "      # Padding nếu độ dài câu chưa bằng max_seq_len\n",
        "      input_ids = input_ids + [pad_id, ]*(max_sequence_length - len(input_ids))\n",
        "    \n",
        "    outputs[idx,:] = np.array(input_ids)\n",
        "  return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jad3MM7ilnUN"
      },
      "outputs": [],
      "source": [
        "from fairseq.data import Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWXKXBUqsFHB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the dictionary  \n",
        "vocab = Dictionary()\n",
        "vocab.add_from_file(\"PhoBERT_base_transformers/dict.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOA4ogLuofpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0600dc-9475-4b1a-8690-87a6649a9b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 971.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1 tensor encode: [63117  1302   884  5958    11   915   222   537   933    39], shape: 256\n",
            "x1 tensor decode:  <s> Học_sinh được nghỉ học bắt dầu từ tháng 3 để tránh dịch covid-19 </s> <pad> <pad> <pad> <pad> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Test encode lines\n",
        "lines = ['Học_sinh được nghỉ học bắt dầu từ tháng 3 để tránh dịch covid-19', 'số lượng ca nhiễm bệnh đã giảm bắt đầu từ tháng 5 nhờ biện pháp mạnh tay']\n",
        "[x1, x2] = convert_lines(lines, vocab, phoBERT.bpe)\n",
        "print('x1 tensor encode: {}, shape: {}'.format(x1[:10], x1.size))\n",
        "print('x1 tensor decode: ', phoBERT.decode(torch.tensor(x1))[:103])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrQRavKsudw"
      },
      "source": [
        "Như vậy ta thấy rằng các câu văn đã được encode về token index. Từ token index có thể decode ngược trở lại thành câu input sau khi đã thêm các token đặc biệt đánh dấu vị trí bắt dầu: `<s>`, kết thúc: `</s>` câu và các vị trí nằm ngoài câu: `<pad>`. Ta sẽ token toàn bộ câu input sang index như sau:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-ua7CMusvFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47cbdcc8-e2f8-4e7e-feae-cd5c2594d466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33759/33759 [02:56<00:00, 191.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape:  (33759, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "X = convert_lines(text_train, vocab, phoBERT.bpe)\n",
        "print('X shape: ', X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf4aCsSLszrP"
      },
      "source": [
        "Sau cùng ta thu được các chuỗi index có kích thước là 256, bằng với kích thước của các câu sau khi đã padding. Tiếp theo ta tạo output y bằng index cho các nhãn của câu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spUJhkMNsyfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0516ac-76a1-4a26-8d66-d71501d9c721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Chinh tri Xa hoi' 'Doi song' 'Khoa hoc' 'Kinh doanh' 'Phap luat'\n",
            " 'Suc khoe' 'The gioi' 'The thao' 'Van hoa' 'Vi tinh']\n",
            "Top 5 classes indices:  [0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "lb.fit(label_train)\n",
        "y = lb.fit_transform(label_train)\n",
        "print(lb.classes_)\n",
        "print('Top 5 classes indices: ', y[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swYHwZA_s4aq"
      },
      "source": [
        "Lưu lại dữ liệu $\\mathbf{X}$ và $\\mathbf{y}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcjvnT8Ts3WH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103de697-75f7-490f-d86b-3c0a15e11324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of X:  33759\n",
            "length of y:  33759\n"
          ]
        }
      ],
      "source": [
        "# Save dữ liệu\n",
        "_save_pkl('PhoBERT_pretrain/X1.pkl', X)\n",
        "_save_pkl('PhoBERT_pretrain/y1.pkl', y)\n",
        "_save_pkl('PhoBERT_pretrain/labelEncoder1.pkl', lb)\n",
        "\n",
        "# Load lại dữ liệu\n",
        "X = _load_pkl('PhoBERT_pretrain/X1.pkl')\n",
        "y = _load_pkl('PhoBERT_pretrain/y1.pkl')\n",
        "\n",
        "print('length of X: ', len(X))\n",
        "print('length of y: ', len(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-BOhZVss7ju"
      },
      "source": [
        "### 8.4. Load model BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTsE43bUs8HQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a454ec83-bf7b-422d-b3bc-10727652496f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.3589, -2.0771, -2.3819, -2.3252, -2.2722, -2.2939, -2.3080, -2.3808,\n",
              "         -2.4188, -2.2526]], grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Load the model in fairseq\n",
        "from fairseq.models.roberta import RobertaModel\n",
        "from fairseq.data.encoders.fastbpe import fastBPE\n",
        "from fairseq.data import Dictionary\n",
        "\n",
        "phoBERT_cls = RobertaModel.from_pretrained('PhoBERT_base_fairseq', checkpoint_file='model.pt')\n",
        "phoBERT_cls.eval()  # disable dropout (or leave in train mode to finetune\n",
        "\n",
        "# Load BPE\n",
        "class BPE():\n",
        "  bpe_codes = 'PhoBERT_base_fairseq/bpe.codes'\n",
        "\n",
        "args = BPE()\n",
        "phoBERT_cls.bpe = fastBPE(args) #Incorporate the BPE encoder into PhoBERT\n",
        "\n",
        "# Add header cho classification với số lượng classes = 10\n",
        "phoBERT_cls.register_classification_head('new_task', num_classes=10)\n",
        "tokens = 'Học_sinh được nghỉ học bắt đầu từ tháng 3 do ảnh hưởng của dịch covid-19'\n",
        "token_idxs = phoBERT_cls.encode(tokens)\n",
        "logprobs = phoBERT_cls.predict('new_task', token_idxs)  # tensor([[-1.1050, -1.0672, -1.1245]], grad_fn=<LogSoftmaxBackward>)\n",
        "logprobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIi0ll-xtA9r"
      },
      "source": [
        "Xây dựng hàm đánh giá mô hình theo 2 metric là accuracy và f1_score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBSIAnLHs-67"
      },
      "source": [
        "### 8.5. Huấn luyện model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcQ1SbWNs_Tq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85995cbc-de5a-458a-f66b-d35a05db3d80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6666666666666666, 0.5333333333333333)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def evaluate(logits, targets):\n",
        "    \"\"\"\n",
        "    Đánh giá model sử dụng accuracy và f1 scores.\n",
        "    Args:\n",
        "        logits (B,C): torch.LongTensor. giá trị predicted logit cho class output.\n",
        "        targets (B): torch.LongTensor. actual target indices.\n",
        "    Returns:\n",
        "        acc (float): the accuracy score\n",
        "        f1 (float): the f1 score\n",
        "    \"\"\"\n",
        "    # Tính accuracy score và f1_score\n",
        "    logits = logits.detach().cpu().numpy()    \n",
        "    y_pred = np.argmax(logits, axis = 1)\n",
        "    targets = targets.detach().cpu().numpy()\n",
        "    f1 = f1_score(targets, y_pred, average='weighted')\n",
        "    acc = accuracy_score(targets, y_pred)\n",
        "    return acc, f1\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "logits = torch.tensor([[0.1, 0.2, 0.7],\n",
        "                       [0.4, 0.1, 0.5],\n",
        "                       [0.1, 0.2, 0.7]]).to(device)\n",
        "targets = torch.tensor([1, 2, 2]).to(device)\n",
        "evaluate(logits, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbJbmoNOtDjE"
      },
      "outputs": [],
      "source": [
        "def validate(valid_loader, model, device):\n",
        "    model.eval()\n",
        "    accs = []\n",
        "    f1s = []\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in valid_loader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs = model.predict('new_task', x_batch)\n",
        "            logits = torch.exp(outputs)\n",
        "            acc, f1 = evaluate(logits, y_batch)\n",
        "            accs.append(acc)\n",
        "            f1s.append(f1)\n",
        "    \n",
        "    mean_acc = np.mean(accs)\n",
        "    mean_f1 = np.mean(f1s)\n",
        "    return mean_acc, mean_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI4iUd6btDLt"
      },
      "source": [
        "Hàm huấn luyện mô hình trên từng epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyEEDWtxtF3x"
      },
      "outputs": [],
      "source": [
        "def trainOnEpoch(train_loader, model, optimizer, epoch, num_epochs, criteria, device, log_aggr = 100):\n",
        "    model.train()\n",
        "    sum_epoch_loss = 0\n",
        "    sum_acc = 0\n",
        "    sum_f1 = 0\n",
        "    start = time.time()\n",
        "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "      x_batch = x_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model.predict('new_task', x_batch)\n",
        "      logits = torch.exp(y_pred)\n",
        "      acc, f1 = evaluate(logits, y_batch)\n",
        "      loss = criteria(y_pred, y_batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      loss_val = loss.item()\n",
        "      sum_epoch_loss += loss_val\n",
        "      sum_acc += acc\n",
        "      sum_f1 += f1\n",
        "      iter_num = epoch * len(train_loader) + i + 1\n",
        "\n",
        "      if i % log_aggr == 0:\n",
        "            print('[TRAIN] epoch %d/%d  observation %d/%d batch loss: %.4f (avg %.4f),  avg acc: %.4f, avg f1: %.4f, (%.2f im/s)'\n",
        "                % (epoch + 1, num_epochs, i, len(train_loader), loss_val, sum_epoch_loss / (i + 1),  sum_acc/(i+1), sum_f1/(i+1),\n",
        "                  len(x_batch) / (time.time() - start)))\n",
        "      start = time.time()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqiIERLDtLW3"
      },
      "source": [
        "Quá trình huấn luyện một model classification trên pytorch sẽ bao gồm những bước chính sau đây:\n",
        "\n",
        "* Khởi tạo DataLoader để quản lý dữ liệu đưa vào huấn luyện và thẩm định.\n",
        "\n",
        "* Thiết lập kiến trúc mô hình.\n",
        "\n",
        "* Khai báo hàm loss function.\n",
        "\n",
        "* Phương pháp optimization giúp tối ưu loss function.\n",
        "\n",
        "* Huấn luyện mô hình qua các epochs.\n",
        "\n",
        "Bên dưới chúng ta sẽ lần lượt thực hiện các bước trên."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7F-RT0l8y8xS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from os.path import join\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.autograd import Variable\n",
        "from torch.backends import cudnn\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzdZ30RmzBY2"
      },
      "source": [
        "* Khởi tạo DataLoader để quản lý dữ liệu đưa vào huấn luyện và thẩm định."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_RBZ4fLzG_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf56377f-b19f-4c34-860d-4e314b019ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n"
          ]
        }
      ],
      "source": [
        "# Load the model in fairseq\n",
        "from fairseq.models.roberta import RobertaModel\n",
        "from fairseq.data.encoders.fastbpe import fastBPE\n",
        "from fairseq.data import Dictionary\n",
        "from transformers.modeling_utils import * \n",
        "from transformers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9o0QnFwzIT8"
      },
      "outputs": [],
      "source": [
        "# Khởi tạo argument\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 6\n",
        "ACCUMULATION_STEPS = 5\n",
        "FOLD = 4\n",
        "LR = 0.0001\n",
        "LR_DC_STEP = 80 \n",
        "LR_DC = 0.1\n",
        "CUR_DIR = os.path.dirname(os.getcwd())\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "FOLD = 4\n",
        "CKPT_PATH2 = 'model_ckpt2'\n",
        "\n",
        "if not os.path.exists(CKPT_PATH2):\n",
        "    os.mkdir(CKPT_PATH2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDd9tqXTtLsp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "339e5533-0596-439c-a54c-647e6b0c30d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for fold 4\n",
            "Load model pretrained!\n",
            "Load BPE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init Optimizer, scheduler, criteria\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n",
            "[TRAIN] epoch 1/20  observation 0/4502 batch loss: 2.2984 (avg 2.2984),  avg acc: 0.1667, avg f1: 0.0556, (1.56 im/s)\n",
            "[TRAIN] epoch 1/20  observation 100/4502 batch loss: 2.2420 (avg 2.3624),  avg acc: 0.1337, avg f1: 0.0633, (21.95 im/s)\n",
            "[TRAIN] epoch 1/20  observation 200/4502 batch loss: 2.2283 (avg 2.3270),  avg acc: 0.1426, avg f1: 0.0672, (21.73 im/s)\n",
            "[TRAIN] epoch 1/20  observation 300/4502 batch loss: 2.3128 (avg 2.3166),  avg acc: 0.1445, avg f1: 0.0671, (20.66 im/s)\n",
            "[TRAIN] epoch 1/20  observation 400/4502 batch loss: 2.0703 (avg 2.3092),  avg acc: 0.1459, avg f1: 0.0676, (20.99 im/s)\n",
            "[TRAIN] epoch 1/20  observation 500/4502 batch loss: 2.4224 (avg 2.3039),  avg acc: 0.1434, avg f1: 0.0667, (20.90 im/s)\n",
            "[TRAIN] epoch 1/20  observation 600/4502 batch loss: 2.1024 (avg 2.2986),  avg acc: 0.1431, avg f1: 0.0673, (20.94 im/s)\n",
            "[TRAIN] epoch 1/20  observation 700/4502 batch loss: 2.4395 (avg 2.2938),  avg acc: 0.1450, avg f1: 0.0693, (20.92 im/s)\n",
            "[TRAIN] epoch 1/20  observation 800/4502 batch loss: 2.1065 (avg 2.2886),  avg acc: 0.1467, avg f1: 0.0698, (20.97 im/s)\n",
            "[TRAIN] epoch 1/20  observation 900/4502 batch loss: 1.9224 (avg 2.2864),  avg acc: 0.1484, avg f1: 0.0706, (20.80 im/s)\n",
            "[TRAIN] epoch 1/20  observation 1000/4502 batch loss: 2.3208 (avg 2.2837),  avg acc: 0.1499, avg f1: 0.0710, (20.93 im/s)\n",
            "[TRAIN] epoch 1/20  observation 1100/4502 batch loss: 2.3553 (avg 2.2830),  avg acc: 0.1490, avg f1: 0.0715, (20.99 im/s)\n",
            "[TRAIN] epoch 1/20  observation 1200/4502 batch loss: 1.9893 (avg 2.2820),  avg acc: 0.1465, avg f1: 0.0704, (21.03 im/s)\n",
            "[TRAIN] epoch 1/20  observation 1300/4502 batch loss: 2.1715 (avg 2.2816),  avg acc: 0.1469, avg f1: 0.0703, (21.14 im/s)\n",
            "[TRAIN] epoch 1/20  observation 1400/4502 batch loss: 2.2214 (avg 2.2808),  avg acc: 0.1478, avg f1: 0.0707, (20.90 im/s)\n",
            "[TRAIN] epoch 1/20  observation 1500/4502 batch loss: 2.1665 (avg 2.2788),  avg acc: 0.1495, avg f1: 0.0722, (21.05 im/s)\n",
            "[TRAIN] epoch 1/20  observation 1600/4502 batch loss: 2.1538 (avg 2.2782),  avg acc: 0.1493, avg f1: 0.0724, (20.88 im/s)\n",
            "[TRAIN] epoch 1/20  observation 1700/4502 batch loss: 2.6633 (avg 2.2793),  avg acc: 0.1474, avg f1: 0.0715, (20.68 im/s)\n",
            "[TRAIN] epoch 1/20  observation 1800/4502 batch loss: 2.2815 (avg 2.2801),  avg acc: 0.1475, avg f1: 0.0713, (20.96 im/s)\n",
            "[TRAIN] epoch 1/20  observation 1900/4502 batch loss: 2.1452 (avg 2.2799),  avg acc: 0.1469, avg f1: 0.0709, (20.90 im/s)\n",
            "[TRAIN] epoch 1/20  observation 2000/4502 batch loss: 2.0882 (avg 2.2791),  avg acc: 0.1459, avg f1: 0.0709, (20.83 im/s)\n",
            "[TRAIN] epoch 1/20  observation 2100/4502 batch loss: 2.3087 (avg 2.2795),  avg acc: 0.1464, avg f1: 0.0711, (20.85 im/s)\n",
            "[TRAIN] epoch 1/20  observation 2200/4502 batch loss: 2.5147 (avg 2.2784),  avg acc: 0.1474, avg f1: 0.0715, (20.82 im/s)\n",
            "[TRAIN] epoch 1/20  observation 2300/4502 batch loss: 2.3104 (avg 2.2777),  avg acc: 0.1480, avg f1: 0.0719, (20.81 im/s)\n",
            "[TRAIN] epoch 1/20  observation 2400/4502 batch loss: 2.3255 (avg 2.2768),  avg acc: 0.1495, avg f1: 0.0724, (21.14 im/s)\n",
            "[TRAIN] epoch 1/20  observation 2500/4502 batch loss: 2.1522 (avg 2.2771),  avg acc: 0.1488, avg f1: 0.0726, (20.48 im/s)\n",
            "[TRAIN] epoch 1/20  observation 2600/4502 batch loss: 2.3821 (avg 2.2772),  avg acc: 0.1481, avg f1: 0.0719, (21.15 im/s)\n",
            "[TRAIN] epoch 1/20  observation 2700/4502 batch loss: 2.1984 (avg 2.2764),  avg acc: 0.1478, avg f1: 0.0721, (20.91 im/s)\n",
            "[TRAIN] epoch 1/20  observation 2800/4502 batch loss: 2.1252 (avg 2.2761),  avg acc: 0.1479, avg f1: 0.0718, (21.08 im/s)\n",
            "[TRAIN] epoch 1/20  observation 2900/4502 batch loss: 2.4072 (avg 2.2759),  avg acc: 0.1476, avg f1: 0.0716, (20.81 im/s)\n",
            "[TRAIN] epoch 1/20  observation 3000/4502 batch loss: 2.3719 (avg 2.2756),  avg acc: 0.1472, avg f1: 0.0714, (20.90 im/s)\n",
            "[TRAIN] epoch 1/20  observation 3100/4502 batch loss: 2.2707 (avg 2.2749),  avg acc: 0.1475, avg f1: 0.0714, (20.97 im/s)\n",
            "[TRAIN] epoch 1/20  observation 3200/4502 batch loss: 2.3785 (avg 2.2745),  avg acc: 0.1480, avg f1: 0.0719, (21.04 im/s)\n",
            "[TRAIN] epoch 1/20  observation 3300/4502 batch loss: 2.4357 (avg 2.2738),  avg acc: 0.1483, avg f1: 0.0718, (20.77 im/s)\n",
            "[TRAIN] epoch 1/20  observation 3400/4502 batch loss: 2.1762 (avg 2.2734),  avg acc: 0.1485, avg f1: 0.0721, (20.83 im/s)\n",
            "[TRAIN] epoch 1/20  observation 3500/4502 batch loss: 2.3263 (avg 2.2727),  avg acc: 0.1490, avg f1: 0.0725, (21.00 im/s)\n",
            "[TRAIN] epoch 1/20  observation 3600/4502 batch loss: 2.4431 (avg 2.2720),  avg acc: 0.1498, avg f1: 0.0729, (20.96 im/s)\n",
            "[TRAIN] epoch 1/20  observation 3700/4502 batch loss: 2.2386 (avg 2.2721),  avg acc: 0.1497, avg f1: 0.0726, (20.92 im/s)\n",
            "[TRAIN] epoch 1/20  observation 3800/4502 batch loss: 2.2220 (avg 2.2722),  avg acc: 0.1496, avg f1: 0.0727, (20.62 im/s)\n",
            "[TRAIN] epoch 1/20  observation 3900/4502 batch loss: 2.4504 (avg 2.2717),  avg acc: 0.1499, avg f1: 0.0727, (20.82 im/s)\n",
            "[TRAIN] epoch 1/20  observation 4000/4502 batch loss: 1.9384 (avg 2.2715),  avg acc: 0.1504, avg f1: 0.0729, (20.91 im/s)\n",
            "[TRAIN] epoch 1/20  observation 4100/4502 batch loss: 2.0300 (avg 2.2712),  avg acc: 0.1502, avg f1: 0.0727, (20.87 im/s)\n",
            "[TRAIN] epoch 1/20  observation 4200/4502 batch loss: 2.3438 (avg 2.2708),  avg acc: 0.1506, avg f1: 0.0731, (20.85 im/s)\n",
            "[TRAIN] epoch 1/20  observation 4300/4502 batch loss: 2.3622 (avg 2.2704),  avg acc: 0.1503, avg f1: 0.0732, (20.92 im/s)\n",
            "[TRAIN] epoch 1/20  observation 4400/4502 batch loss: 2.4375 (avg 2.2699),  avg acc: 0.1508, avg f1: 0.0734, (20.80 im/s)\n",
            "[TRAIN] epoch 1/20  observation 4500/4502 batch loss: 2.5383 (avg 2.2698),  avg acc: 0.1507, avg f1: 0.0734, (20.90 im/s)\n",
            "Epoch 0 validation: acc: 0.1567, f1: 0.1566 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [23:31<7:26:57, 1411.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1\n",
            "[TRAIN] epoch 2/20  observation 0/4502 batch loss: 2.1541 (avg 2.1541),  avg acc: 0.0000, avg f1: 0.0000, (14.88 im/s)\n",
            "[TRAIN] epoch 2/20  observation 100/4502 batch loss: 2.2946 (avg 2.2804),  avg acc: 0.1502, avg f1: 0.0687, (20.18 im/s)\n",
            "[TRAIN] epoch 2/20  observation 200/4502 batch loss: 2.2882 (avg 2.2643),  avg acc: 0.1609, avg f1: 0.0735, (20.82 im/s)\n",
            "[TRAIN] epoch 2/20  observation 300/4502 batch loss: 2.3820 (avg 2.2574),  avg acc: 0.1645, avg f1: 0.0767, (21.16 im/s)\n",
            "[TRAIN] epoch 2/20  observation 400/4502 batch loss: 2.4394 (avg 2.2549),  avg acc: 0.1638, avg f1: 0.0787, (20.80 im/s)\n",
            "[TRAIN] epoch 2/20  observation 500/4502 batch loss: 2.2386 (avg 2.2547),  avg acc: 0.1613, avg f1: 0.0792, (20.83 im/s)\n",
            "[TRAIN] epoch 2/20  observation 600/4502 batch loss: 2.3147 (avg 2.2561),  avg acc: 0.1583, avg f1: 0.0797, (20.85 im/s)\n",
            "[TRAIN] epoch 2/20  observation 700/4502 batch loss: 2.2749 (avg 2.2546),  avg acc: 0.1600, avg f1: 0.0815, (20.81 im/s)\n",
            "[TRAIN] epoch 2/20  observation 800/4502 batch loss: 2.2644 (avg 2.2531),  avg acc: 0.1604, avg f1: 0.0811, (20.91 im/s)\n",
            "[TRAIN] epoch 2/20  observation 900/4502 batch loss: 2.1963 (avg 2.2560),  avg acc: 0.1609, avg f1: 0.0813, (20.89 im/s)\n",
            "[TRAIN] epoch 2/20  observation 1000/4502 batch loss: 2.2228 (avg 2.2576),  avg acc: 0.1602, avg f1: 0.0804, (20.94 im/s)\n",
            "[TRAIN] epoch 2/20  observation 1100/4502 batch loss: 2.1555 (avg 2.2577),  avg acc: 0.1605, avg f1: 0.0805, (20.77 im/s)\n",
            "[TRAIN] epoch 2/20  observation 1200/4502 batch loss: 2.3072 (avg 2.2580),  avg acc: 0.1604, avg f1: 0.0811, (20.83 im/s)\n",
            "[TRAIN] epoch 2/20  observation 1300/4502 batch loss: 2.2490 (avg 2.2590),  avg acc: 0.1580, avg f1: 0.0791, (21.00 im/s)\n",
            "[TRAIN] epoch 2/20  observation 1400/4502 batch loss: 2.1889 (avg 2.2596),  avg acc: 0.1574, avg f1: 0.0789, (20.80 im/s)\n",
            "[TRAIN] epoch 2/20  observation 1500/4502 batch loss: 2.1961 (avg 2.2594),  avg acc: 0.1566, avg f1: 0.0790, (20.78 im/s)\n",
            "[TRAIN] epoch 2/20  observation 1600/4502 batch loss: 2.1107 (avg 2.2581),  avg acc: 0.1567, avg f1: 0.0790, (21.02 im/s)\n",
            "[TRAIN] epoch 2/20  observation 1700/4502 batch loss: 2.1337 (avg 2.2585),  avg acc: 0.1572, avg f1: 0.0803, (21.05 im/s)\n",
            "[TRAIN] epoch 2/20  observation 1800/4502 batch loss: 2.2420 (avg 2.2589),  avg acc: 0.1569, avg f1: 0.0798, (20.88 im/s)\n",
            "[TRAIN] epoch 2/20  observation 1900/4502 batch loss: 2.2317 (avg 2.2587),  avg acc: 0.1572, avg f1: 0.0802, (20.70 im/s)\n",
            "[TRAIN] epoch 2/20  observation 2000/4502 batch loss: 2.1894 (avg 2.2597),  avg acc: 0.1568, avg f1: 0.0796, (21.04 im/s)\n",
            "[TRAIN] epoch 2/20  observation 2100/4502 batch loss: 2.2198 (avg 2.2596),  avg acc: 0.1568, avg f1: 0.0793, (20.93 im/s)\n",
            "[TRAIN] epoch 2/20  observation 2200/4502 batch loss: 2.0898 (avg 2.2591),  avg acc: 0.1564, avg f1: 0.0796, (20.78 im/s)\n",
            "[TRAIN] epoch 2/20  observation 2300/4502 batch loss: 2.3135 (avg 2.2593),  avg acc: 0.1562, avg f1: 0.0797, (20.77 im/s)\n",
            "[TRAIN] epoch 2/20  observation 2400/4502 batch loss: 2.1454 (avg 2.2596),  avg acc: 0.1551, avg f1: 0.0793, (20.97 im/s)\n",
            "[TRAIN] epoch 2/20  observation 2500/4502 batch loss: 2.1476 (avg 2.2594),  avg acc: 0.1552, avg f1: 0.0790, (20.88 im/s)\n",
            "[TRAIN] epoch 2/20  observation 2600/4502 batch loss: 2.3058 (avg 2.2590),  avg acc: 0.1553, avg f1: 0.0789, (20.98 im/s)\n",
            "[TRAIN] epoch 2/20  observation 2700/4502 batch loss: 2.4303 (avg 2.2584),  avg acc: 0.1556, avg f1: 0.0792, (21.09 im/s)\n",
            "[TRAIN] epoch 2/20  observation 2800/4502 batch loss: 2.1343 (avg 2.2573),  avg acc: 0.1563, avg f1: 0.0794, (20.72 im/s)\n",
            "[TRAIN] epoch 2/20  observation 2900/4502 batch loss: 2.2490 (avg 2.2578),  avg acc: 0.1562, avg f1: 0.0794, (20.96 im/s)\n",
            "[TRAIN] epoch 2/20  observation 3000/4502 batch loss: 2.0968 (avg 2.2583),  avg acc: 0.1557, avg f1: 0.0793, (20.81 im/s)\n",
            "[TRAIN] epoch 2/20  observation 3100/4502 batch loss: 2.0364 (avg 2.2577),  avg acc: 0.1565, avg f1: 0.0795, (20.84 im/s)\n",
            "[TRAIN] epoch 2/20  observation 3200/4502 batch loss: 2.2550 (avg 2.2580),  avg acc: 0.1560, avg f1: 0.0791, (21.12 im/s)\n",
            "[TRAIN] epoch 2/20  observation 3300/4502 batch loss: 2.2098 (avg 2.2583),  avg acc: 0.1556, avg f1: 0.0788, (21.20 im/s)\n",
            "[TRAIN] epoch 2/20  observation 3400/4502 batch loss: 2.1822 (avg 2.2581),  avg acc: 0.1555, avg f1: 0.0786, (21.08 im/s)\n",
            "[TRAIN] epoch 2/20  observation 3500/4502 batch loss: 2.2253 (avg 2.2583),  avg acc: 0.1552, avg f1: 0.0781, (21.13 im/s)\n",
            "[TRAIN] epoch 2/20  observation 3600/4502 batch loss: 2.2613 (avg 2.2583),  avg acc: 0.1551, avg f1: 0.0780, (20.94 im/s)\n",
            "[TRAIN] epoch 2/20  observation 3700/4502 batch loss: 2.1423 (avg 2.2583),  avg acc: 0.1550, avg f1: 0.0781, (20.79 im/s)\n",
            "[TRAIN] epoch 2/20  observation 3800/4502 batch loss: 2.3137 (avg 2.2582),  avg acc: 0.1549, avg f1: 0.0781, (20.85 im/s)\n",
            "[TRAIN] epoch 2/20  observation 3900/4502 batch loss: 2.3469 (avg 2.2586),  avg acc: 0.1551, avg f1: 0.0778, (20.89 im/s)\n",
            "[TRAIN] epoch 2/20  observation 4000/4502 batch loss: 2.1393 (avg 2.2584),  avg acc: 0.1551, avg f1: 0.0781, (20.78 im/s)\n",
            "[TRAIN] epoch 2/20  observation 4100/4502 batch loss: 2.3343 (avg 2.2581),  avg acc: 0.1556, avg f1: 0.0784, (20.63 im/s)\n",
            "[TRAIN] epoch 2/20  observation 4200/4502 batch loss: 2.1768 (avg 2.2580),  avg acc: 0.1558, avg f1: 0.0787, (21.06 im/s)\n",
            "[TRAIN] epoch 2/20  observation 4300/4502 batch loss: 2.3326 (avg 2.2585),  avg acc: 0.1555, avg f1: 0.0785, (21.03 im/s)\n",
            "[TRAIN] epoch 2/20  observation 4400/4502 batch loss: 2.2303 (avg 2.2588),  avg acc: 0.1553, avg f1: 0.0785, (20.99 im/s)\n",
            "[TRAIN] epoch 2/20  observation 4500/4502 batch loss: 2.2531 (avg 2.2584),  avg acc: 0.1556, avg f1: 0.0786, (20.73 im/s)\n",
            "Epoch 1 validation: acc: 0.1567, f1: 0.1566 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [46:55<7:02:11, 1407.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  2\n",
            "[TRAIN] epoch 3/20  observation 0/4502 batch loss: 2.4871 (avg 2.4871),  avg acc: 0.0000, avg f1: 0.0000, (16.61 im/s)\n",
            "[TRAIN] epoch 3/20  observation 100/4502 batch loss: 2.1602 (avg 2.2659),  avg acc: 0.1650, avg f1: 0.0726, (20.19 im/s)\n",
            "[TRAIN] epoch 3/20  observation 200/4502 batch loss: 2.3294 (avg 2.2600),  avg acc: 0.1683, avg f1: 0.0751, (21.16 im/s)\n",
            "[TRAIN] epoch 3/20  observation 300/4502 batch loss: 2.4422 (avg 2.2610),  avg acc: 0.1722, avg f1: 0.0770, (20.94 im/s)\n",
            "[TRAIN] epoch 3/20  observation 400/4502 batch loss: 2.1749 (avg 2.2587),  avg acc: 0.1712, avg f1: 0.0780, (20.84 im/s)\n",
            "[TRAIN] epoch 3/20  observation 500/4502 batch loss: 2.1128 (avg 2.2602),  avg acc: 0.1667, avg f1: 0.0754, (20.87 im/s)\n",
            "[TRAIN] epoch 3/20  observation 600/4502 batch loss: 2.1679 (avg 2.2588),  avg acc: 0.1647, avg f1: 0.0740, (20.87 im/s)\n",
            "[TRAIN] epoch 3/20  observation 700/4502 batch loss: 2.3577 (avg 2.2603),  avg acc: 0.1660, avg f1: 0.0747, (20.69 im/s)\n",
            "[TRAIN] epoch 3/20  observation 800/4502 batch loss: 2.2632 (avg 2.2598),  avg acc: 0.1638, avg f1: 0.0736, (20.87 im/s)\n",
            "[TRAIN] epoch 3/20  observation 900/4502 batch loss: 2.3003 (avg 2.2603),  avg acc: 0.1635, avg f1: 0.0733, (20.87 im/s)\n",
            "[TRAIN] epoch 3/20  observation 1000/4502 batch loss: 2.4549 (avg 2.2615),  avg acc: 0.1617, avg f1: 0.0726, (21.17 im/s)\n",
            "[TRAIN] epoch 3/20  observation 1100/4502 batch loss: 2.2701 (avg 2.2622),  avg acc: 0.1602, avg f1: 0.0714, (21.01 im/s)\n",
            "[TRAIN] epoch 3/20  observation 1200/4502 batch loss: 2.6461 (avg 2.2620),  avg acc: 0.1595, avg f1: 0.0708, (21.11 im/s)\n",
            "[TRAIN] epoch 3/20  observation 1300/4502 batch loss: 2.3451 (avg 2.2615),  avg acc: 0.1586, avg f1: 0.0702, (20.77 im/s)\n",
            "[TRAIN] epoch 3/20  observation 1400/4502 batch loss: 2.2961 (avg 2.2596),  avg acc: 0.1600, avg f1: 0.0707, (20.88 im/s)\n",
            "[TRAIN] epoch 3/20  observation 1500/4502 batch loss: 2.1421 (avg 2.2569),  avg acc: 0.1619, avg f1: 0.0722, (20.69 im/s)\n",
            "[TRAIN] epoch 3/20  observation 1600/4502 batch loss: 2.2294 (avg 2.2564),  avg acc: 0.1622, avg f1: 0.0725, (20.73 im/s)\n",
            "[TRAIN] epoch 3/20  observation 1700/4502 batch loss: 2.1042 (avg 2.2577),  avg acc: 0.1612, avg f1: 0.0719, (20.82 im/s)\n",
            "[TRAIN] epoch 3/20  observation 1800/4502 batch loss: 2.3062 (avg 2.2582),  avg acc: 0.1609, avg f1: 0.0718, (21.14 im/s)\n",
            "[TRAIN] epoch 3/20  observation 1900/4502 batch loss: 1.9560 (avg 2.2583),  avg acc: 0.1611, avg f1: 0.0721, (20.65 im/s)\n",
            "[TRAIN] epoch 3/20  observation 2000/4502 batch loss: 2.4012 (avg 2.2584),  avg acc: 0.1602, avg f1: 0.0715, (20.69 im/s)\n",
            "[TRAIN] epoch 3/20  observation 2100/4502 batch loss: 2.4488 (avg 2.2578),  avg acc: 0.1601, avg f1: 0.0714, (21.00 im/s)\n",
            "[TRAIN] epoch 3/20  observation 2200/4502 batch loss: 2.2806 (avg 2.2580),  avg acc: 0.1593, avg f1: 0.0711, (20.86 im/s)\n",
            "[TRAIN] epoch 3/20  observation 2300/4502 batch loss: 2.2217 (avg 2.2564),  avg acc: 0.1595, avg f1: 0.0709, (21.06 im/s)\n",
            "[TRAIN] epoch 3/20  observation 2400/4502 batch loss: 2.2553 (avg 2.2573),  avg acc: 0.1596, avg f1: 0.0710, (20.64 im/s)\n",
            "[TRAIN] epoch 3/20  observation 2500/4502 batch loss: 2.1783 (avg 2.2575),  avg acc: 0.1586, avg f1: 0.0706, (20.82 im/s)\n",
            "[TRAIN] epoch 3/20  observation 2600/4502 batch loss: 2.0743 (avg 2.2570),  avg acc: 0.1588, avg f1: 0.0707, (20.65 im/s)\n",
            "[TRAIN] epoch 3/20  observation 2700/4502 batch loss: 2.4274 (avg 2.2575),  avg acc: 0.1583, avg f1: 0.0705, (20.79 im/s)\n",
            "[TRAIN] epoch 3/20  observation 2800/4502 batch loss: 2.2827 (avg 2.2578),  avg acc: 0.1577, avg f1: 0.0702, (20.79 im/s)\n",
            "[TRAIN] epoch 3/20  observation 2900/4502 batch loss: 2.3004 (avg 2.2578),  avg acc: 0.1576, avg f1: 0.0703, (20.93 im/s)\n",
            "[TRAIN] epoch 3/20  observation 3000/4502 batch loss: 2.2861 (avg 2.2583),  avg acc: 0.1571, avg f1: 0.0700, (20.83 im/s)\n",
            "[TRAIN] epoch 3/20  observation 3100/4502 batch loss: 2.1731 (avg 2.2580),  avg acc: 0.1575, avg f1: 0.0702, (21.24 im/s)\n",
            "[TRAIN] epoch 3/20  observation 3200/4502 batch loss: 2.3402 (avg 2.2581),  avg acc: 0.1568, avg f1: 0.0698, (21.15 im/s)\n",
            "[TRAIN] epoch 3/20  observation 3300/4502 batch loss: 2.1567 (avg 2.2581),  avg acc: 0.1566, avg f1: 0.0695, (20.72 im/s)\n",
            "[TRAIN] epoch 3/20  observation 3400/4502 batch loss: 2.2397 (avg 2.2581),  avg acc: 0.1565, avg f1: 0.0695, (20.87 im/s)\n",
            "[TRAIN] epoch 3/20  observation 3500/4502 batch loss: 2.2508 (avg 2.2580),  avg acc: 0.1564, avg f1: 0.0694, (20.87 im/s)\n",
            "[TRAIN] epoch 3/20  observation 3600/4502 batch loss: 2.1423 (avg 2.2575),  avg acc: 0.1568, avg f1: 0.0698, (20.68 im/s)\n",
            "[TRAIN] epoch 3/20  observation 3700/4502 batch loss: 2.0629 (avg 2.2573),  avg acc: 0.1569, avg f1: 0.0699, (20.41 im/s)\n",
            "[TRAIN] epoch 3/20  observation 3800/4502 batch loss: 2.1700 (avg 2.2570),  avg acc: 0.1567, avg f1: 0.0697, (20.87 im/s)\n",
            "[TRAIN] epoch 3/20  observation 3900/4502 batch loss: 2.2079 (avg 2.2571),  avg acc: 0.1565, avg f1: 0.0696, (21.14 im/s)\n",
            "[TRAIN] epoch 3/20  observation 4000/4502 batch loss: 2.0224 (avg 2.2568),  avg acc: 0.1573, avg f1: 0.0701, (21.00 im/s)\n",
            "[TRAIN] epoch 3/20  observation 4100/4502 batch loss: 2.2672 (avg 2.2563),  avg acc: 0.1573, avg f1: 0.0700, (20.74 im/s)\n",
            "[TRAIN] epoch 3/20  observation 4200/4502 batch loss: 2.2123 (avg 2.2562),  avg acc: 0.1573, avg f1: 0.0699, (20.84 im/s)\n",
            "[TRAIN] epoch 3/20  observation 4300/4502 batch loss: 2.1482 (avg 2.2561),  avg acc: 0.1573, avg f1: 0.0699, (21.12 im/s)\n",
            "[TRAIN] epoch 3/20  observation 4400/4502 batch loss: 2.2683 (avg 2.2560),  avg acc: 0.1572, avg f1: 0.0698, (21.11 im/s)\n",
            "[TRAIN] epoch 3/20  observation 4500/4502 batch loss: 2.2867 (avg 2.2561),  avg acc: 0.1570, avg f1: 0.0698, (20.83 im/s)\n",
            "Epoch 2 validation: acc: 0.1567, f1: 0.1566 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [1:10:22<6:38:42, 1407.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  3\n",
            "[TRAIN] epoch 4/20  observation 0/4502 batch loss: 2.0902 (avg 2.0902),  avg acc: 0.3333, avg f1: 0.1667, (17.55 im/s)\n",
            "[TRAIN] epoch 4/20  observation 100/4502 batch loss: 2.4587 (avg 2.2446),  avg acc: 0.1815, avg f1: 0.0792, (20.03 im/s)\n",
            "[TRAIN] epoch 4/20  observation 200/4502 batch loss: 2.1567 (avg 2.2475),  avg acc: 0.1675, avg f1: 0.0726, (20.60 im/s)\n",
            "[TRAIN] epoch 4/20  observation 300/4502 batch loss: 2.3126 (avg 2.2490),  avg acc: 0.1645, avg f1: 0.0721, (21.14 im/s)\n",
            "[TRAIN] epoch 4/20  observation 400/4502 batch loss: 2.3717 (avg 2.2495),  avg acc: 0.1675, avg f1: 0.0741, (21.07 im/s)\n",
            "[TRAIN] epoch 4/20  observation 500/4502 batch loss: 2.3437 (avg 2.2444),  avg acc: 0.1647, avg f1: 0.0737, (20.84 im/s)\n",
            "[TRAIN] epoch 4/20  observation 600/4502 batch loss: 2.4673 (avg 2.2466),  avg acc: 0.1633, avg f1: 0.0731, (20.77 im/s)\n",
            "[TRAIN] epoch 4/20  observation 700/4502 batch loss: 2.4271 (avg 2.2478),  avg acc: 0.1629, avg f1: 0.0728, (20.73 im/s)\n",
            "[TRAIN] epoch 4/20  observation 800/4502 batch loss: 2.0783 (avg 2.2470),  avg acc: 0.1621, avg f1: 0.0723, (20.97 im/s)\n",
            "[TRAIN] epoch 4/20  observation 900/4502 batch loss: 2.1282 (avg 2.2487),  avg acc: 0.1604, avg f1: 0.0712, (21.00 im/s)\n",
            "[TRAIN] epoch 4/20  observation 1000/4502 batch loss: 2.4469 (avg 2.2504),  avg acc: 0.1580, avg f1: 0.0698, (21.13 im/s)\n",
            "[TRAIN] epoch 4/20  observation 1100/4502 batch loss: 2.3310 (avg 2.2519),  avg acc: 0.1589, avg f1: 0.0706, (20.81 im/s)\n",
            "[TRAIN] epoch 4/20  observation 1200/4502 batch loss: 2.3403 (avg 2.2523),  avg acc: 0.1561, avg f1: 0.0695, (20.86 im/s)\n",
            "[TRAIN] epoch 4/20  observation 1300/4502 batch loss: 2.1213 (avg 2.2522),  avg acc: 0.1571, avg f1: 0.0702, (20.78 im/s)\n",
            "[TRAIN] epoch 4/20  observation 1400/4502 batch loss: 2.2290 (avg 2.2520),  avg acc: 0.1583, avg f1: 0.0711, (21.05 im/s)\n",
            "[TRAIN] epoch 4/20  observation 1500/4502 batch loss: 2.1475 (avg 2.2508),  avg acc: 0.1588, avg f1: 0.0713, (20.87 im/s)\n",
            "[TRAIN] epoch 4/20  observation 1600/4502 batch loss: 2.1099 (avg 2.2496),  avg acc: 0.1594, avg f1: 0.0718, (20.86 im/s)\n",
            "[TRAIN] epoch 4/20  observation 1700/4502 batch loss: 2.0952 (avg 2.2502),  avg acc: 0.1594, avg f1: 0.0715, (20.74 im/s)\n",
            "[TRAIN] epoch 4/20  observation 1800/4502 batch loss: 2.5818 (avg 2.2508),  avg acc: 0.1594, avg f1: 0.0715, (20.90 im/s)\n",
            "[TRAIN] epoch 4/20  observation 1900/4502 batch loss: 2.3616 (avg 2.2512),  avg acc: 0.1590, avg f1: 0.0713, (20.53 im/s)\n",
            "[TRAIN] epoch 4/20  observation 2000/4502 batch loss: 2.2952 (avg 2.2508),  avg acc: 0.1598, avg f1: 0.0718, (20.76 im/s)\n",
            "[TRAIN] epoch 4/20  observation 2100/4502 batch loss: 2.0075 (avg 2.2515),  avg acc: 0.1584, avg f1: 0.0712, (21.09 im/s)\n",
            "[TRAIN] epoch 4/20  observation 2200/4502 batch loss: 2.4428 (avg 2.2522),  avg acc: 0.1574, avg f1: 0.0708, (21.15 im/s)\n",
            "[TRAIN] epoch 4/20  observation 2300/4502 batch loss: 2.0636 (avg 2.2531),  avg acc: 0.1563, avg f1: 0.0704, (20.89 im/s)\n",
            "[TRAIN] epoch 4/20  observation 2400/4502 batch loss: 2.1561 (avg 2.2530),  avg acc: 0.1558, avg f1: 0.0703, (20.80 im/s)\n",
            "[TRAIN] epoch 4/20  observation 2500/4502 batch loss: 2.4272 (avg 2.2526),  avg acc: 0.1558, avg f1: 0.0704, (20.95 im/s)\n",
            "[TRAIN] epoch 4/20  observation 2600/4502 batch loss: 2.1569 (avg 2.2521),  avg acc: 0.1567, avg f1: 0.0711, (21.15 im/s)\n",
            "[TRAIN] epoch 4/20  observation 2700/4502 batch loss: 2.1850 (avg 2.2522),  avg acc: 0.1570, avg f1: 0.0713, (20.94 im/s)\n",
            "[TRAIN] epoch 4/20  observation 2800/4502 batch loss: 2.2119 (avg 2.2521),  avg acc: 0.1577, avg f1: 0.0719, (21.01 im/s)\n",
            "[TRAIN] epoch 4/20  observation 2900/4502 batch loss: 2.3151 (avg 2.2527),  avg acc: 0.1574, avg f1: 0.0717, (21.07 im/s)\n",
            "[TRAIN] epoch 4/20  observation 3000/4502 batch loss: 2.2923 (avg 2.2529),  avg acc: 0.1564, avg f1: 0.0711, (20.99 im/s)\n",
            "[TRAIN] epoch 4/20  observation 3100/4502 batch loss: 2.4242 (avg 2.2527),  avg acc: 0.1569, avg f1: 0.0717, (20.98 im/s)\n",
            "[TRAIN] epoch 4/20  observation 3200/4502 batch loss: 2.3665 (avg 2.2533),  avg acc: 0.1566, avg f1: 0.0715, (21.06 im/s)\n",
            "[TRAIN] epoch 4/20  observation 3300/4502 batch loss: 2.4380 (avg 2.2537),  avg acc: 0.1564, avg f1: 0.0716, (20.96 im/s)\n",
            "[TRAIN] epoch 4/20  observation 3400/4502 batch loss: 2.2689 (avg 2.2539),  avg acc: 0.1563, avg f1: 0.0716, (20.67 im/s)\n",
            "[TRAIN] epoch 4/20  observation 3500/4502 batch loss: 2.2779 (avg 2.2542),  avg acc: 0.1560, avg f1: 0.0715, (20.86 im/s)\n",
            "[TRAIN] epoch 4/20  observation 3600/4502 batch loss: 2.1239 (avg 2.2537),  avg acc: 0.1566, avg f1: 0.0721, (20.98 im/s)\n",
            "[TRAIN] epoch 4/20  observation 3700/4502 batch loss: 2.3531 (avg 2.2545),  avg acc: 0.1562, avg f1: 0.0720, (20.93 im/s)\n",
            "[TRAIN] epoch 4/20  observation 3800/4502 batch loss: 2.2642 (avg 2.2544),  avg acc: 0.1561, avg f1: 0.0722, (20.75 im/s)\n",
            "[TRAIN] epoch 4/20  observation 3900/4502 batch loss: 2.1431 (avg 2.2543),  avg acc: 0.1560, avg f1: 0.0724, (20.94 im/s)\n",
            "[TRAIN] epoch 4/20  observation 4000/4502 batch loss: 2.0850 (avg 2.2538),  avg acc: 0.1565, avg f1: 0.0731, (21.10 im/s)\n",
            "[TRAIN] epoch 4/20  observation 4100/4502 batch loss: 2.2459 (avg 2.2535),  avg acc: 0.1571, avg f1: 0.0737, (20.74 im/s)\n",
            "[TRAIN] epoch 4/20  observation 4200/4502 batch loss: 2.3637 (avg 2.2539),  avg acc: 0.1566, avg f1: 0.0735, (21.18 im/s)\n",
            "[TRAIN] epoch 4/20  observation 4300/4502 batch loss: 2.2876 (avg 2.2537),  avg acc: 0.1568, avg f1: 0.0735, (20.87 im/s)\n",
            "[TRAIN] epoch 4/20  observation 4400/4502 batch loss: 2.2611 (avg 2.2544),  avg acc: 0.1559, avg f1: 0.0732, (20.89 im/s)\n",
            "[TRAIN] epoch 4/20  observation 4500/4502 batch loss: 2.2634 (avg 2.2544),  avg acc: 0.1562, avg f1: 0.0735, (20.93 im/s)\n",
            "Epoch 3 validation: acc: 0.1567, f1: 0.1566 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [1:33:58<6:16:08, 1410.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  4\n",
            "[TRAIN] epoch 5/20  observation 0/4502 batch loss: 2.0876 (avg 2.0876),  avg acc: 0.1667, avg f1: 0.0476, (16.93 im/s)\n",
            "[TRAIN] epoch 5/20  observation 100/4502 batch loss: 2.1414 (avg 2.2379),  avg acc: 0.1700, avg f1: 0.0839, (20.40 im/s)\n",
            "[TRAIN] epoch 5/20  observation 200/4502 batch loss: 2.1323 (avg 2.2453),  avg acc: 0.1750, avg f1: 0.0841, (20.97 im/s)\n",
            "[TRAIN] epoch 5/20  observation 300/4502 batch loss: 2.2617 (avg 2.2478),  avg acc: 0.1711, avg f1: 0.0817, (21.34 im/s)\n",
            "[TRAIN] epoch 5/20  observation 400/4502 batch loss: 2.3442 (avg 2.2504),  avg acc: 0.1692, avg f1: 0.0794, (20.62 im/s)\n",
            "[TRAIN] epoch 5/20  observation 500/4502 batch loss: 2.1281 (avg 2.2459),  avg acc: 0.1710, avg f1: 0.0803, (20.97 im/s)\n",
            "[TRAIN] epoch 5/20  observation 600/4502 batch loss: 2.2721 (avg 2.2504),  avg acc: 0.1689, avg f1: 0.0786, (21.10 im/s)\n",
            "[TRAIN] epoch 5/20  observation 700/4502 batch loss: 2.2294 (avg 2.2518),  avg acc: 0.1669, avg f1: 0.0770, (20.82 im/s)\n",
            "[TRAIN] epoch 5/20  observation 800/4502 batch loss: 2.2667 (avg 2.2535),  avg acc: 0.1650, avg f1: 0.0761, (20.81 im/s)\n",
            "[TRAIN] epoch 5/20  observation 900/4502 batch loss: 2.1747 (avg 2.2540),  avg acc: 0.1622, avg f1: 0.0744, (20.94 im/s)\n",
            "[TRAIN] epoch 5/20  observation 1000/4502 batch loss: 2.3848 (avg 2.2547),  avg acc: 0.1600, avg f1: 0.0734, (20.87 im/s)\n",
            "[TRAIN] epoch 5/20  observation 1100/4502 batch loss: 2.3523 (avg 2.2561),  avg acc: 0.1591, avg f1: 0.0730, (20.81 im/s)\n",
            "[TRAIN] epoch 5/20  observation 1200/4502 batch loss: 2.3013 (avg 2.2561),  avg acc: 0.1590, avg f1: 0.0729, (20.88 im/s)\n",
            "[TRAIN] epoch 5/20  observation 1300/4502 batch loss: 2.0992 (avg 2.2548),  avg acc: 0.1591, avg f1: 0.0730, (20.89 im/s)\n",
            "[TRAIN] epoch 5/20  observation 1400/4502 batch loss: 2.1305 (avg 2.2546),  avg acc: 0.1583, avg f1: 0.0725, (20.97 im/s)\n",
            "[TRAIN] epoch 5/20  observation 1500/4502 batch loss: 2.2884 (avg 2.2529),  avg acc: 0.1616, avg f1: 0.0747, (21.01 im/s)\n",
            "[TRAIN] epoch 5/20  observation 1600/4502 batch loss: 2.1872 (avg 2.2532),  avg acc: 0.1613, avg f1: 0.0745, (20.74 im/s)\n",
            "[TRAIN] epoch 5/20  observation 1700/4502 batch loss: 2.2467 (avg 2.2537),  avg acc: 0.1612, avg f1: 0.0744, (20.83 im/s)\n",
            "[TRAIN] epoch 5/20  observation 1800/4502 batch loss: 2.2655 (avg 2.2550),  avg acc: 0.1601, avg f1: 0.0737, (20.89 im/s)\n",
            "[TRAIN] epoch 5/20  observation 1900/4502 batch loss: 2.4072 (avg 2.2550),  avg acc: 0.1595, avg f1: 0.0733, (20.82 im/s)\n",
            "[TRAIN] epoch 5/20  observation 2000/4502 batch loss: 2.1163 (avg 2.2543),  avg acc: 0.1599, avg f1: 0.0736, (20.73 im/s)\n",
            "[TRAIN] epoch 5/20  observation 2100/4502 batch loss: 2.2170 (avg 2.2542),  avg acc: 0.1596, avg f1: 0.0735, (20.73 im/s)\n",
            "[TRAIN] epoch 5/20  observation 2200/4502 batch loss: 2.3028 (avg 2.2541),  avg acc: 0.1607, avg f1: 0.0744, (20.87 im/s)\n",
            "[TRAIN] epoch 5/20  observation 2300/4502 batch loss: 2.1341 (avg 2.2541),  avg acc: 0.1602, avg f1: 0.0739, (21.05 im/s)\n",
            "[TRAIN] epoch 5/20  observation 2400/4502 batch loss: 2.3368 (avg 2.2533),  avg acc: 0.1603, avg f1: 0.0739, (20.83 im/s)\n",
            "[TRAIN] epoch 5/20  observation 2500/4502 batch loss: 2.4612 (avg 2.2533),  avg acc: 0.1601, avg f1: 0.0739, (20.81 im/s)\n",
            "[TRAIN] epoch 5/20  observation 2600/4502 batch loss: 2.3274 (avg 2.2533),  avg acc: 0.1597, avg f1: 0.0740, (20.93 im/s)\n",
            "[TRAIN] epoch 5/20  observation 2700/4502 batch loss: 2.2399 (avg 2.2539),  avg acc: 0.1595, avg f1: 0.0742, (20.82 im/s)\n",
            "[TRAIN] epoch 5/20  observation 2800/4502 batch loss: 2.2616 (avg 2.2541),  avg acc: 0.1585, avg f1: 0.0737, (21.07 im/s)\n",
            "[TRAIN] epoch 5/20  observation 2900/4502 batch loss: 2.2029 (avg 2.2541),  avg acc: 0.1590, avg f1: 0.0746, (20.89 im/s)\n",
            "[TRAIN] epoch 5/20  observation 3000/4502 batch loss: 2.1609 (avg 2.2544),  avg acc: 0.1589, avg f1: 0.0751, (21.10 im/s)\n",
            "[TRAIN] epoch 5/20  observation 3100/4502 batch loss: 2.4005 (avg 2.2554),  avg acc: 0.1580, avg f1: 0.0749, (21.17 im/s)\n",
            "[TRAIN] epoch 5/20  observation 3200/4502 batch loss: 2.2456 (avg 2.2554),  avg acc: 0.1585, avg f1: 0.0759, (21.06 im/s)\n",
            "[TRAIN] epoch 5/20  observation 3300/4502 batch loss: 2.2159 (avg 2.2556),  avg acc: 0.1581, avg f1: 0.0759, (21.02 im/s)\n",
            "[TRAIN] epoch 5/20  observation 3400/4502 batch loss: 2.0479 (avg 2.2560),  avg acc: 0.1575, avg f1: 0.0764, (20.69 im/s)\n",
            "[TRAIN] epoch 5/20  observation 3500/4502 batch loss: 2.3784 (avg 2.2560),  avg acc: 0.1574, avg f1: 0.0770, (20.87 im/s)\n",
            "[TRAIN] epoch 5/20  observation 3600/4502 batch loss: 2.4053 (avg 2.2562),  avg acc: 0.1576, avg f1: 0.0781, (20.98 im/s)\n",
            "[TRAIN] epoch 5/20  observation 3700/4502 batch loss: 2.2859 (avg 2.2556),  avg acc: 0.1577, avg f1: 0.0790, (20.91 im/s)\n",
            "[TRAIN] epoch 5/20  observation 3800/4502 batch loss: 2.4069 (avg 2.2557),  avg acc: 0.1578, avg f1: 0.0797, (20.81 im/s)\n",
            "[TRAIN] epoch 5/20  observation 3900/4502 batch loss: 2.3834 (avg 2.2555),  avg acc: 0.1580, avg f1: 0.0805, (20.98 im/s)\n",
            "[TRAIN] epoch 5/20  observation 4000/4502 batch loss: 2.3076 (avg 2.2557),  avg acc: 0.1582, avg f1: 0.0813, (20.96 im/s)\n"
          ]
        }
      ],
      "source": [
        "# Khởi tạo DataLoader\n",
        "splits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(X, y))\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(splits):\n",
        "    best_score = 0\n",
        "    if fold != FOLD:\n",
        "        continue\n",
        "    print(\"Training for fold {}\".format(fold))\n",
        "    \n",
        "    # Create dataset\n",
        "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X[train_idx],dtype=torch.long), torch.tensor(y[train_idx],dtype=torch.long))\n",
        "    valid_dataset = torch.utils.data.TensorDataset(torch.tensor(X[val_idx],dtype=torch.long), torch.tensor(y[val_idx],dtype=torch.long))\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Khởi tạo model:\n",
        "    MODEL_LAST_CKPT = os.path.join(CKPT_PATH2, 'latest_checkpoint.pth.tar')\n",
        "    if os.path.exists(MODEL_LAST_CKPT):\n",
        "      print('Load checkpoint model!')\n",
        "      phoBERT_cls = torch.load(MODEL_LAST_CKPT)\n",
        "    else:\n",
        "      print('Load model pretrained!')\n",
        "      # Load the model in fairseq\n",
        "      from fairseq.models.roberta import RobertaModel\n",
        "      from fairseq.data.encoders.fastbpe import fastBPE\n",
        "      from fairseq.data import Dictionary\n",
        "\n",
        "      phoBERT_cls = RobertaModel.from_pretrained('PhoBERT_base_fairseq', checkpoint_file='model.pt')\n",
        "      phoBERT_cls.eval()  # disable dropout (or leave in train mode to finetune\n",
        "\n",
        "      # # Load BPE\n",
        "      # class BPE():\n",
        "      #   bpe_codes = 'PhoBERT_base_fairseq/bpe.codes'\n",
        "\n",
        "      # args = BPE()\n",
        "      # phoBERT_cls.bpe = fastBPE(args) #Incorporate the BPE encoder into PhoBERT\n",
        "\n",
        "      # Add header cho classification với số lượng classes = 10\n",
        "      phoBERT_cls.register_classification_head('new_task', num_classes=10)\n",
        "      \n",
        "    ## Load BPE\n",
        "    print('Load BPE')\n",
        "    class BPE():\n",
        "      bpe_codes = 'PhoBERT_base_fairseq/bpe.codes'\n",
        "\n",
        "    args = BPE()\n",
        "    phoBERT_cls.bpe = fastBPE(args) #Incorporate the BPE encoder into PhoBERT\n",
        "    phoBERT_cls.to(DEVICE)\n",
        "\n",
        "    # Khởi tạo optimizer và scheduler, criteria\n",
        "    print('Init Optimizer, scheduler, criteria')\n",
        "    param_optimizer = list(phoBERT_cls.named_parameters())\n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "\n",
        "    num_train_optimization_steps = int(EPOCHS*len(train_dataset)/BATCH_SIZE/ACCUMULATION_STEPS)\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=LR, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_train_optimization_steps)  # scheduler với linear warmup\n",
        "    scheduler0 = get_constant_schedule(optimizer)  # scheduler với hằng số\n",
        "    # optimizer = optim.Adam(phoBERT_cls.parameters(), LR)\n",
        "    criteria = nn.NLLLoss()\n",
        "    # scheduler = StepLR(optimizer, step_size = LR_DC_STEP, gamma = LR_DC)\n",
        "    avg_loss = 0.\n",
        "    avg_accuracy = 0.\n",
        "    frozen = True\n",
        "    for epoch in tqdm(range(EPOCHS)):\n",
        "        # warm up tại epoch đầu tiên, sau epoch đầu sẽ phá băng các layers\n",
        "        if epoch > 0 and frozen:\n",
        "            for child in phoBERT_cls.children():\n",
        "                for param in child.parameters():\n",
        "                    param.requires_grad = True\n",
        "            frozen = False\n",
        "            del scheduler0\n",
        "            torch.cuda.empty_cache()\n",
        "        # Train model on EPOCH\n",
        "        print('Epoch: ', epoch)\n",
        "        trainOnEpoch(train_loader=train_loader, model=phoBERT_cls, optimizer=optimizer, epoch=epoch, num_epochs=EPOCHS, criteria=criteria, device=DEVICE, log_aggr=100)\n",
        "        # scheduler.step(epoch = epoch)\n",
        "        # Phá băng layers sau epoch đầu tiên\n",
        "        if not frozen:\n",
        "            scheduler.step()\n",
        "        else:\n",
        "            scheduler0.step()\n",
        "        optimizer.zero_grad()\n",
        "        # Validate on validation set\n",
        "        acc, f1 = validate(valid_loader, phoBERT_cls, device=DEVICE)\n",
        "        print('Epoch {} validation: acc: {:.4f}, f1: {:.4f} \\n'.format(epoch, acc, f1))\n",
        "\n",
        "        # Store best model checkpoint\n",
        "        ckpt_dict = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': phoBERT_cls.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "        # Save model checkpoint into 'latest_checkpoint.pth.tar'\n",
        "        torch.save(ckpt_dict, MODEL_LAST_CKPT)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1UskTMptJmPuIWR_MhSadxElGB1FOPIEK",
      "authorship_tag": "ABX9TyMuEeBz6MyPjT/GgUNo1eit",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}